{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Yolov5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Speed: 0.0ms preprocess, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 0.0ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.7ms\n",
      "Speed: 0.0ms preprocess, 125.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 0.0ms preprocess, 117.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.7ms\n",
      "Speed: 0.0ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 118.1ms\n",
      "Speed: 2.3ms preprocess, 118.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 116.3ms\n",
      "Speed: 0.0ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 2.4ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.7ms\n",
      "Speed: 3.2ms preprocess, 128.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 136.0ms\n",
      "Speed: 0.0ms preprocess, 136.0ms inference, 12.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.0ms\n",
      "Speed: 2.0ms preprocess, 130.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.6ms\n",
      "Speed: 1.1ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.5ms\n",
      "Speed: 0.0ms preprocess, 115.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.2ms\n",
      "Speed: 1.7ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.2ms\n",
      "Speed: 0.9ms preprocess, 135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.7ms\n",
      "Speed: 1.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.5ms\n",
      "Speed: 0.0ms preprocess, 124.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.0ms\n",
      "Speed: 0.0ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.5ms\n",
      "Speed: 1.6ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 1.3ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cat, 138.9ms\n",
      "Speed: 0.0ms preprocess, 138.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.4ms\n",
      "Speed: 0.0ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 backpack, 113.6ms\n",
      "Speed: 0.5ms preprocess, 113.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 backpack, 143.0ms\n",
      "Speed: 2.8ms preprocess, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.5ms\n",
      "Speed: 4.4ms preprocess, 128.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.8ms\n",
      "Speed: 0.0ms preprocess, 136.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.5ms\n",
      "Speed: 0.0ms preprocess, 115.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.2ms\n",
      "Speed: 0.0ms preprocess, 115.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.3ms\n",
      "Speed: 0.0ms preprocess, 123.3ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 128.2ms\n",
      "Speed: 1.8ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 114.8ms\n",
      "Speed: 0.0ms preprocess, 114.8ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 115.4ms\n",
      "Speed: 0.0ms preprocess, 115.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 113.8ms\n",
      "Speed: 0.0ms preprocess, 113.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 123.5ms\n",
      "Speed: 0.0ms preprocess, 123.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 115.0ms\n",
      "Speed: 0.0ms preprocess, 115.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 123.6ms\n",
      "Speed: 1.0ms preprocess, 123.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 5.4ms preprocess, 144.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.2ms\n",
      "Speed: 1.0ms preprocess, 113.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.6ms\n",
      "Speed: 0.0ms preprocess, 130.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.9ms\n",
      "Speed: 0.0ms preprocess, 113.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 113.5ms\n",
      "Speed: 2.3ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 129.5ms\n",
      "Speed: 1.0ms preprocess, 129.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 bottles, 1 chair, 116.6ms\n",
      "Speed: 1.9ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.3ms\n",
      "Speed: 0.0ms preprocess, 131.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.2ms\n",
      "Speed: 0.0ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.7ms\n",
      "Speed: 1.5ms preprocess, 114.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.6ms\n",
      "Speed: 2.6ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 0.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.4ms\n",
      "Speed: 0.0ms preprocess, 124.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 3.3ms preprocess, 146.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.1ms\n",
      "Speed: 0.0ms preprocess, 133.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.9ms\n",
      "Speed: 0.0ms preprocess, 134.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.2ms\n",
      "Speed: 0.0ms preprocess, 131.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.8ms\n",
      "Speed: 4.1ms preprocess, 145.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 146.1ms\n",
      "Speed: 1.5ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.1ms\n",
      "Speed: 0.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 137.3ms\n",
      "Speed: 0.0ms preprocess, 137.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 145.5ms\n",
      "Speed: 1.0ms preprocess, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 132.0ms\n",
      "Speed: 1.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 146.9ms\n",
      "Speed: 1.0ms preprocess, 146.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 146.5ms\n",
      "Speed: 1.0ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 1 chair, 131.3ms\n",
      "Speed: 1.0ms preprocess, 131.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 116.3ms\n",
      "Speed: 0.0ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.0ms\n",
      "Speed: 1.1ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 131.7ms\n",
      "Speed: 0.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 132.6ms\n",
      "Speed: 0.0ms preprocess, 132.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 159.3ms\n",
      "Speed: 1.0ms preprocess, 159.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 1 chair, 147.3ms\n",
      "Speed: 1.0ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 128.9ms\n",
      "Speed: 2.7ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 129.7ms\n",
      "Speed: 1.5ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 146.3ms\n",
      "Speed: 2.0ms preprocess, 146.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 146.3ms\n",
      "Speed: 2.0ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 128.4ms\n",
      "Speed: 0.0ms preprocess, 128.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 133.1ms\n",
      "Speed: 0.0ms preprocess, 133.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 132.3ms\n",
      "Speed: 0.0ms preprocess, 132.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 132.2ms\n",
      "Speed: 1.6ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 129.6ms\n",
      "Speed: 1.0ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 bottles, 115.2ms\n",
      "Speed: 0.0ms preprocess, 115.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 121.2ms\n",
      "Speed: 0.0ms preprocess, 121.2ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 130.3ms\n",
      "Speed: 1.0ms preprocess, 130.3ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 145.6ms\n",
      "Speed: 2.0ms preprocess, 145.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 139.7ms\n",
      "Speed: 0.0ms preprocess, 139.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 couch, 149.3ms\n",
      "Speed: 0.0ms preprocess, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 126.3ms\n",
      "Speed: 0.6ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 couch, 116.6ms\n",
      "Speed: 1.3ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 129.4ms\n",
      "Speed: 2.0ms preprocess, 129.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 115.1ms\n",
      "Speed: 0.0ms preprocess, 115.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 129.3ms\n",
      "Speed: 2.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 152.7ms\n",
      "Speed: 4.2ms preprocess, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 116.0ms\n",
      "Speed: 0.0ms preprocess, 116.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 115.7ms\n",
      "Speed: 0.0ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 114.6ms\n",
      "Speed: 1.0ms preprocess, 114.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 couch, 132.7ms\n",
      "Speed: 0.0ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 146.5ms\n",
      "Speed: 3.8ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 120.2ms\n",
      "Speed: 0.0ms preprocess, 120.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 114.6ms\n",
      "Speed: 1.0ms preprocess, 114.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 1 couch, 99.4ms\n",
      "Speed: 0.0ms preprocess, 99.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 114.8ms\n",
      "Speed: 0.0ms preprocess, 114.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 3 chairs, 131.3ms\n",
      "Speed: 0.0ms preprocess, 131.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 132.9ms\n",
      "Speed: 0.0ms preprocess, 132.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 116.5ms\n",
      "Speed: 0.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 115.9ms\n",
      "Speed: 0.0ms preprocess, 115.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 132.6ms\n",
      "Speed: 0.0ms preprocess, 132.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 160.8ms\n",
      "Speed: 4.9ms preprocess, 160.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 3 chairs, 131.5ms\n",
      "Speed: 1.0ms preprocess, 131.5ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 149.4ms\n",
      "Speed: 4.0ms preprocess, 149.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 134.1ms\n",
      "Speed: 0.0ms preprocess, 134.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 147.9ms\n",
      "Speed: 0.0ms preprocess, 147.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 132.5ms\n",
      "Speed: 0.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 135.7ms\n",
      "Speed: 0.0ms preprocess, 135.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 114.1ms\n",
      "Speed: 0.0ms preprocess, 114.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 149.7ms\n",
      "Speed: 3.2ms preprocess, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 132.2ms\n",
      "Speed: 0.0ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 115.3ms\n",
      "Speed: 0.0ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 117.0ms\n",
      "Speed: 1.0ms preprocess, 117.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 113.6ms\n",
      "Speed: 0.0ms preprocess, 113.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 132.2ms\n",
      "Speed: 0.0ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 2 chairs, 137.6ms\n",
      "Speed: 0.0ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 chair, 148.7ms\n",
      "Speed: 0.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 133.6ms\n",
      "Speed: 1.0ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 0.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 132.4ms\n",
      "Speed: 0.0ms preprocess, 132.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 132.1ms\n",
      "Speed: 0.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 0.0ms preprocess, 148.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.3ms\n",
      "Speed: 0.0ms preprocess, 149.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.2ms\n",
      "Speed: 3.3ms preprocess, 163.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 1.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.9ms\n",
      "Speed: 0.0ms preprocess, 132.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.4ms\n",
      "Speed: 4.3ms preprocess, 145.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 backpack, 131.5ms\n",
      "Speed: 1.0ms preprocess, 131.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.6ms\n",
      "Speed: 0.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 130.1ms\n",
      "Speed: 1.0ms preprocess, 130.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.4ms\n",
      "Speed: 0.0ms preprocess, 116.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.7ms\n",
      "Speed: 1.1ms preprocess, 133.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.6ms\n",
      "Speed: 1.0ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.5ms\n",
      "Speed: 5.7ms preprocess, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.8ms\n",
      "Speed: 1.1ms preprocess, 129.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.8ms\n",
      "Speed: 1.0ms preprocess, 114.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.8ms\n",
      "Speed: 2.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = YOLO('yolov5s.pt')  # YOLOv5s is a small pre-trained model\n",
    "\n",
    "# Open a video file or real-time camera\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide a video path\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model.predict(source=frame, save=False)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('YOLOv5 Detection', annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SSD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'https' not implemented (file: 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2/saved_model.pb')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the pre-trained SSD MobileNet model from TensorFlow Hub\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m ssd_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m category_index \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBicycle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMotorcycle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirplane\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m7\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m8\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruck\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraffic Light\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Function to detect objects\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:912\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    911\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 912\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:1016\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m   1012\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m   1015\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1016\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1018\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:59\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     62\u001b[0m       path_helpers\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     63\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     64\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:104\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Parse the SavedModel protocol buffer.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_pb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m file_io\u001b[38;5;241m.\u001b[39mFileIO(path_to_pb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    106\u001b[0m     file_content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:298\u001b[0m, in \u001b[0;36mfile_exists\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgfile.Exists\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfile_exists\u001b[39m(filename):\n\u001b[1;32m--> 298\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfile_exists_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python312\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:290\u001b[0m, in \u001b[0;36mfile_exists_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determines whether a path exists or not.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m>>> with open(\"/tmp/x\", \"w\") as f:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m  errors.OpError: Propagates any errors reported by the FileSystem API.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m   \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileExists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError:\n\u001b[0;32m    292\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'https' not implemented (file: 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2/saved_model.pb')"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained SSD MobileNet model from TensorFlow Hub\n",
    "ssd_model = tf.saved_model.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "category_index = {1: \"Person\", 2: \"Bicycle\", 3: \"Car\", 4: \"Motorcycle\", 5: \"Airplane\", 6: \"Bus\", 7: \"Train\", 8: \"Truck\", 9: \"Boat\", 10: \"Traffic Light\"}\n",
    "\n",
    "# Function to detect objects\n",
    "def detect_objects(frame, model):\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    # Extract information from detections\n",
    "    detection_boxes = detections[\"detection_boxes\"][0].numpy()\n",
    "    detection_scores = detections[\"detection_scores\"][0].numpy()\n",
    "    detection_classes = detections[\"detection_classes\"][0].numpy().astype(np.int32)\n",
    "\n",
    "    return detection_boxes, detection_scores, detection_classes\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_boxes(frame, boxes, scores, classes, threshold=0.5):\n",
    "    h, w, _ = frame.shape\n",
    "    for i, box in enumerate(boxes):\n",
    "        if scores[i] > threshold:\n",
    "            y1, x1, y2, x2 = box\n",
    "            x1, x2, y1, y2 = int(x1 * w), int(x2 * w), int(y1 * h), int(y2 * h)\n",
    "            class_name = category_index.get(classes[i], \"Unknown\")\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{class_name}: {scores[i]:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "# Open video capture (real-time or pre-recorded video)\n",
    "video_path = 0  # Use 0 for webcam or replace with video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize and normalize the frame\n",
    "    input_frame = cv2.resize(frame, (300, 300))\n",
    "    input_frame = np.array(input_frame) / 255.0\n",
    "\n",
    "    # Detect objects\n",
    "    boxes, scores, classes = detect_objects(input_frame, ssd_model)\n",
    "\n",
    "    # Draw boxes on the original frame\n",
    "    output_frame = draw_boxes(frame, boxes, scores, classes)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(\"SSD Object Detection\", output_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
