{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Yolov5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-12-21 Python-3.12.0 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown: No flags detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-12-21 Python-3.12.0 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown: No flags detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-12-21 Python-3.12.0 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\Vibha Narayan/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown: No flags detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_flag_yolov(image_path, model_path='yolov5s.pt'):\n",
    "    \"\"\"\n",
    "    Uses YOLOv5 for object detection to identify flags in an image.\n",
    "    Detects regions of interest (e.g., red and white bands) for flag identification.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model_path (str): Path to the YOLOv5 model (default is 'yolov5s.pt').\n",
    "\n",
    "    Returns:\n",
    "        str: \"Indonesia\", \"Poland\", or \"Unknown\" based on detected flag.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load YOLOv5 model\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
    "\n",
    "        # Perform detection\n",
    "        results = model(image_path)\n",
    "\n",
    "        # Parse results\n",
    "        detections = results.pandas().xyxy[0]  # Pandas DataFrame of results\n",
    "        \n",
    "        # Filter detections for flags (based on custom training or predefined classes)\n",
    "        flag_detections = detections[detections['name'].str.contains(\"flag\", case=False, na=False)]\n",
    "\n",
    "        if flag_detections.empty:\n",
    "            return \"Unknown: No flags detected\"\n",
    "\n",
    "        # Load the image for further analysis\n",
    "        image = cv2.imread(image_path)\n",
    "        image_resized = cv2.resize(image, (640, 640))\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Analyze detected regions to determine if it's Indonesia or Poland\n",
    "        for _, row in flag_detections.iterrows():\n",
    "            x_min, y_min, x_max, y_max = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "\n",
    "            # Crop the detected flag region\n",
    "            flag_region = image_rgb[y_min:y_max, x_min:x_max]\n",
    "            \n",
    "            # Resize for consistent analysis\n",
    "            flag_region = cv2.resize(flag_region, (300, 200))\n",
    "\n",
    "            # Split into top and bottom halves\n",
    "            mid_line = flag_region.shape[0] // 2\n",
    "            top_half = flag_region[:mid_line, :, :]\n",
    "            bottom_half = flag_region[mid_line:, :, :]\n",
    "\n",
    "            # Calculate mean color for each half\n",
    "            top_mean_color = np.mean(top_half, axis=(0, 1))\n",
    "            bottom_mean_color = np.mean(bottom_half, axis=(0, 1))\n",
    "\n",
    "            # Determine flag based on color positions\n",
    "            is_top_red = top_mean_color[0] > 150 and top_mean_color[1] < 100 and top_mean_color[2] < 100\n",
    "            is_bottom_white = bottom_mean_color[0] > 180 and bottom_mean_color[1] > 100 and bottom_mean_color[2] > 180\n",
    "\n",
    "            is_top_white = top_mean_color[0] > 150 and top_mean_color[1] > 100 and top_mean_color[2] > 100\n",
    "            is_bottom_red = bottom_mean_color[0] > 180 and bottom_mean_color[1] < 180 and bottom_mean_color[2] < 100\n",
    "\n",
    "            if is_top_red and is_bottom_white:\n",
    "                return \"Indonesia\"\n",
    "            elif is_top_white and is_bottom_red:\n",
    "                return \"Poland\"\n",
    "\n",
    "        return \"Unknown: Flag type not determined\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the YOLOv5-based flag detection function\n",
    "if __name__ == \"__main__\":\n",
    "    refined_flag_result = detect_flag_yolov(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Poland Flag.png\")\n",
    "    print(refined_flag_result)\n",
    "\n",
    "    refined_flag_result = detect_flag_yolov(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Indonesian Flag.png\")\n",
    "    print(refined_flag_result)\n",
    "\n",
    "    refined_flag_result = detect_flag_yolov(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Indonesia Flag.png\")\n",
    "    print(refined_flag_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 umbrella, 1 kite, 260.0ms\n",
      "Speed: 20.3ms preprocess, 260.0ms inference, 16.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Unknown: Flag regions not detected\n",
      "\n",
      "0: 448x640 1 bed, 180.9ms\n",
      "Speed: 3.4ms preprocess, 180.9ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Unknown: Flag regions not detected\n",
      "\n",
      "0: 448x640 (no detections), 181.6ms\n",
      "Speed: 8.0ms preprocess, 181.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Unknown: Flag regions not detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def detect_flag_with_yolov8(image_path):\n",
    "    # Load the YOLOv8 model\n",
    "    model = YOLO('yolov8n.pt')  # Replace with your custom model if trained\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model.predict(image_rgb)\n",
    "\n",
    "    # Extract bounding boxes and class labels\n",
    "    boxes = results[0].boxes  # Boxes for the first image\n",
    "    annotations = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].numpy()  # Bounding box coordinates\n",
    "        cls = int(box.cls[0])  # Class index\n",
    "        conf = float(box.conf[0])  # Confidence score\n",
    "        annotations.append((x1, y1, x2, y2, cls, conf))\n",
    "\n",
    "    # Analyze detected boxes for red and white regions\n",
    "    red_boxes = []\n",
    "    white_boxes = []\n",
    "\n",
    "    for x1, y1, x2, y2, cls, conf in annotations:\n",
    "        if conf < 0.2:  # Skip low-confidence detections\n",
    "            continue\n",
    "        # Assuming class 0 is red and class 1 is white (adjust as needed)\n",
    "        if cls == 0:  # Red\n",
    "            red_boxes.append((x1, y1, x2, y2))\n",
    "        elif cls == 1:  # White\n",
    "            white_boxes.append((x1, y1, x2, y2))\n",
    "\n",
    "    if not red_boxes or not white_boxes:\n",
    "        return \"Unknown: Flag regions not detected\"\n",
    "\n",
    "    # Use the largest red and white regions for decision-making\n",
    "    largest_red = max(red_boxes, key=lambda box: (box[2] - box[0]) * (box[3] - box[1]))\n",
    "    largest_white = max(white_boxes, key=lambda box: (box[2] - box[0]) * (box[3] - box[1]))\n",
    "\n",
    "    # Get the center Y-coordinates of the largest red and white regions\n",
    "    red_y_center = (largest_red[1] + largest_red[3]) / 2\n",
    "    white_y_center = (largest_white[1] + largest_white[3]) / 2\n",
    "\n",
    "    # Determine the flag type\n",
    "    if red_y_center < white_y_center:\n",
    "        flag = \"Indonesia\"  # Red is above white\n",
    "    else:\n",
    "        flag = \"Poland\"  # White is above red\n",
    "\n",
    "    # Draw bounding boxes on the image\n",
    "    for x1, y1, x2, y2 in red_boxes:\n",
    "        cv2.rectangle(image_rgb, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 3)  # Red bounding box\n",
    "    for x1, y1, x2, y2 in white_boxes:\n",
    "        cv2.rectangle(image_rgb, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 3)  # White bounding box\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Detected Flag\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return flag\n",
    "\n",
    "# Test the function with your images\n",
    "result1 = detect_flag_with_yolov8(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Poland Flag.png\")\n",
    "print(result1)\n",
    "result2 = detect_flag_with_yolov8(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Indonesian Flag.png\")\n",
    "print(result2)\n",
    "result3 = detect_flag_with_yolov8(r\"C:\\Users\\Vibha Narayan\\OneDrive\\Pictures\\Screenshots\\Indonesia Flag.png\")\n",
    "print(result3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
